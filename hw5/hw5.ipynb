{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiadFMKrQJ_x"
      },
      "source": [
        "%matplotlib inline\n",
        "from sklearn import datasets, model_selection, tree, metrics, ensemble, linear_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kkYVkVpkMWk"
      },
      "source": [
        "# Задание 1. (4 балла)\n",
        "\n",
        "\n",
        "Вам нужно реализовать градиентный бустинг для задачи регрессии на датасете boston.\n",
        "\n",
        "Заполните кодом строчки в TODO. Запустите, сделайте предсказание, проверьте что все ок, и выведите rmse ошибку."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NraW6CJPQRVZ",
        "outputId": "db551de4-c02b-4dd7-d8f0-9a478d6545ea"
      },
      "source": [
        "data = datasets.load_boston()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGdUiNSMQhAe"
      },
      "source": [
        "X = data['data']\n",
        "y = data['target']"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYIASWiMQjec"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=41)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjK2mlEig7yu"
      },
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Параметрами с которыми вы хотите обучать деревья\n",
        "TREE_PARAMS_DICT = {'max_depth': 1}\n",
        "# Параметр tau (learning_rate) для вашего GB\n",
        "TAU = 0.05\n",
        "ITERS = 100\n",
        "\n",
        "\n",
        "class SimpleGB(BaseEstimator):\n",
        "    def __init__(self, tree_params_dict, iters, tau):\n",
        "        self.tree_params_dict = tree_params_dict\n",
        "        self.iters = iters\n",
        "        self.tau = tau\n",
        "        \n",
        "    def fit(self, X_data, y_data):\n",
        "        self.base_algo = DecisionTreeRegressor(**self.tree_params_dict).fit(X_data, y_data)\n",
        "        self.estimators = []\n",
        "        curr_pred = self.base_algo.predict(X_data)\n",
        "        for iter_num in range(self.iters):\n",
        "            # Нужно посчитать градиент функции потерь\n",
        "            # For regression L(y, a) = 0.5 * (a-y)**2\n",
        "            #.               L'(y, a) = a - y ==> antigradient = y - a, where a = curr_pred\n",
        "            grad = curr_pred - y_data# TODO\n",
        "            # Нужно обучить DecisionTreeRegressor предсказывать антиградиент\n",
        "            # Не забудьте про self.tree_params_dict\n",
        "            algo = DecisionTreeRegressor(**self.tree_params_dict).fit(X_data, -grad) # TODO\n",
        "\n",
        "            self.estimators.append(algo)\n",
        "            # Обновите предсказания в каждой точке\n",
        "            # Just add contribution of the current tree to the predictions:\n",
        "            curr_pred += self.tau * algo.predict(X_data) # TODO\n",
        "        return self\n",
        "    \n",
        "    def predict(self, X_data):\n",
        "        # Предсказание на данных\n",
        "        res = self.base_algo.predict(X_data)\n",
        "        for estimator in self.estimators:\n",
        "            res += self.tau * estimator.predict(X_data)\n",
        "        \n",
        "        return res"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's run the model:"
      ],
      "metadata": {
        "id": "-QDQ4HvBMEW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simple_gb = SimpleGB(TREE_PARAMS_DICT, ITERS, TAU)"
      ],
      "metadata": {
        "id": "vRv0mZq3KV8g"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "XII5jMVOKpk6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "- np.mean(cross_val_score(simple_gb, X_train, y_train, cv=5, scoring='neg_root_mean_squared_error'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hF81nFBdKzjL",
        "outputId": "c6129257-37a4-46ae-f360-5a4af2348aec"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.135524138817064"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the results on the test set:"
      ],
      "metadata": {
        "id": "cYktUAxwMLAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simple_gb.fit(X_train, y_train)\n",
        "y_pred = simple_gb.predict(X_test)\n",
        "\n",
        "np.sqrt(mean_squared_error(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZawemwILZ-0",
        "outputId": "df525f16-b583-46fa-afbc-2c7c14459fdf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.671875533154961"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's compare with Linear Regression (just to see if the `rmse` score above is within the norm):"
      ],
      "metadata": {
        "id": "Jfjp6ZxYNFMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ],
      "metadata": {
        "id": "YnFNbnQ9LBgY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LinearRegression()"
      ],
      "metadata": {
        "id": "OenXyxw_LGtl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "- np.mean(cross_val_score(lr, X_train, y_train, cv=5, scoring='neg_root_mean_squared_error'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AYZBRHWLJRY",
        "outputId": "83b27b52-a3f8-44a9-dd44-19f5d93a3d70"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.1027151819431396"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr.fit(X_train, y_train)\n",
        "y_pred = lr.predict(X_test)\n",
        "\n",
        "np.sqrt(mean_squared_error(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uw7K3enKNilE",
        "outputId": "723a82d1-fb11-4d24-a64f-6416fea0f630"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.597800668458814"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It works (:"
      ],
      "metadata": {
        "id": "KcB9ZLTMNn8r"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvVnhF1Bn8l1"
      },
      "source": [
        "# Задание 2. (1 балл)\n",
        "\n",
        "Датасет маленький, давайте возьмем что-нибудь поинтереснее. Например, HR.csv (лежит в папке с занятием 30_11/trees).\n",
        "\n",
        "Подгрузите датасет, сделайте split на train/test, random_state = 42. Выберите любую модель - xgboost, lightgbm, catboost. И проведите несколько экспериментов.\n",
        "\n",
        "Подберите оптимальные с точки зрения метрики качества параметры алгоритмов, например:\n",
        "* глубину\n",
        "* количество деревьев\n",
        "\n",
        "Посмотрите в документации, с какими еще параметрами можно поиграться. Но не делайте слишком большой поиск - будет долго считаться. \n",
        "\n",
        "Обучите несколько различных моделей, сделайте блендинг и сравните качество. \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold"
      ],
      "metadata": {
        "id": "8RGZHxPHOmz_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ewRn80Vq9HV"
      },
      "source": [
        "df = pd.read_csv('HR.csv')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zuzJy0ahOqDC",
        "outputId": "cf090e3c-41f9-4e03-84b4-d6c62d5e15de"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>last_evaluation</th>\n",
              "      <th>number_project</th>\n",
              "      <th>average_montly_hours</th>\n",
              "      <th>time_spend_company</th>\n",
              "      <th>Work_accident</th>\n",
              "      <th>left</th>\n",
              "      <th>promotion_last_5years</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.53</td>\n",
              "      <td>2</td>\n",
              "      <td>157</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.86</td>\n",
              "      <td>5</td>\n",
              "      <td>262</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.88</td>\n",
              "      <td>7</td>\n",
              "      <td>272</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.87</td>\n",
              "      <td>5</td>\n",
              "      <td>223</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.52</td>\n",
              "      <td>2</td>\n",
              "      <td>159</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   last_evaluation  number_project  ...  left  promotion_last_5years\n",
              "0             0.53               2  ...     1                      0\n",
              "1             0.86               5  ...     0                      0\n",
              "2             0.88               7  ...     1                      0\n",
              "3             0.87               5  ...     1                      0\n",
              "4             0.52               2  ...     1                      0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lUKOt2qPIde",
        "outputId": "7161f3a5-5eda-4938-ce75-8fd54cbc8c9b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14999, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['promotion_last_5years'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzHgDU9KOq0A",
        "outputId": "99077ef8-9b0d-4069-aa82-7599c8411aa2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:, :-1].copy()\n",
        "y = df.iloc[:, -1].copy()"
      ],
      "metadata": {
        "id": "7mLFtYy2Ox_S"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Observation:\n",
        "- We see that the dataset is highly unbalanced:"
      ],
      "metadata": {
        "id": "oFho2kHBm0Sd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J45qw8yzmvDp",
        "outputId": "3477200f-00a5-4858-fd5e-0bb6e18c2f1c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.021268084538969265"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we make train-test split and cross-validation accordingly:"
      ],
      "metadata": {
        "id": "YtI9JEQ9nKwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(X,y, stratify=y, random_state=41)"
      ],
      "metadata": {
        "id": "sczhARUSPAFE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_clf = XGBClassifier()"
      ],
      "metadata": {
        "id": "vTFV82OHPHSP"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params_grid = {\n",
        "    'n_estimators': range(50, 200, 50),\n",
        "    'max_depth': [4,6,8, 10],\n",
        "    'colsample_bylevel': [0.4,0.6,0.8, 1.0]\n",
        "}"
      ],
      "metadata": {
        "id": "DpQtrromP23E"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take data imbalanced into account for grid search\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=41)\n",
        "grid_search = GridSearchCV(xgb_clf, params_grid, scoring=\"neg_log_loss\", n_jobs=-1, cv=kfold)"
      ],
      "metadata": {
        "id": "JTjKE1ftQoaf"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iC6q2cPmQ8k9",
        "outputId": "f91357b7-efb9-426f-b1cf-c00f55a91843"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=41, shuffle=True),\n",
              "             estimator=XGBClassifier(), n_jobs=-1,\n",
              "             param_grid={'colsample_bylevel': [0.4, 0.6, 0.8, 1.0],\n",
              "                         'max_depth': [4, 6, 8, 10],\n",
              "                         'n_estimators': range(50, 200, 50)},\n",
              "             scoring='neg_log_loss')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_results = pd.DataFrame(grid_search.cv_results_)[['param_colsample_bylevel', 'param_max_depth', 'param_n_estimators', 'mean_test_score', 'rank_test_score']].sort_values(by='rank_test_score')\n",
        "cv_results.rename(columns={'mean_test_score': 'mean_test_neg_log_loss'}, inplace=True)\n",
        "cv_results.columns = cv_results.columns.str.replace('param_', '')\n",
        "\n",
        "cv_results.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vrYW_SBDRAgA",
        "outputId": "ed11a60c-9354-4f3f-d19f-76c70c095274"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>colsample_bylevel</th>\n",
              "      <th>max_depth</th>\n",
              "      <th>n_estimators</th>\n",
              "      <th>mean_test_neg_log_loss</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>50</td>\n",
              "      <td>-0.086522</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.8</td>\n",
              "      <td>10</td>\n",
              "      <td>100</td>\n",
              "      <td>-0.086918</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>100</td>\n",
              "      <td>-0.087068</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.8</td>\n",
              "      <td>10</td>\n",
              "      <td>50</td>\n",
              "      <td>-0.087218</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>100</td>\n",
              "      <td>-0.087237</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   colsample_bylevel max_depth  ... mean_test_neg_log_loss  rank_test_score\n",
              "45                 1        10  ...              -0.086522                1\n",
              "34               0.8        10  ...              -0.086918                2\n",
              "43                 1         8  ...              -0.087068                3\n",
              "33               0.8        10  ...              -0.087218                4\n",
              "46                 1        10  ...              -0.087237                5\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Observations:\n",
        "\n",
        "- We see that the best set of parameters are those that:\n",
        "  - have the deepest trees (`max_depth` - $8$ and $10$).\n",
        "  - use most of the features when doing split at each level (`colsample_bylevel` - $80\\%$ and $100\\%$ of the features)."
      ],
      "metadata": {
        "id": "DwmempCBzGDR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try blending (model comparison at the end):"
      ],
      "metadata": {
        "id": "MzmFk_C3Ukvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "V4F-pefSPdAX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Blender(BaseEstimator):\n",
        "  def __init__(self, estimators, meta_estimator):\n",
        "    self.estimators = estimators\n",
        "    self.meta_estimator = meta_estimator\n",
        "    self.predictions_by_model = dict()\n",
        "\n",
        "  \n",
        "  def fit(self, X, y):\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, stratify=y, random_state=41)\n",
        "\n",
        "    X_val_meta = X_val\n",
        "\n",
        "    for model_name, estimator in self.estimators.items():\n",
        "\n",
        "      estimator.fit(X_train, y_train)\n",
        "      pred = estimator.predict(X_val)\n",
        "\n",
        "      X_val_meta = np.c_[X_val_meta, pred]\n",
        "    \n",
        "\n",
        "    self.meta_estimator.fit(X_val_meta, y_val)\n",
        "\n",
        "\n",
        "    \n",
        "  def predict(self, X):\n",
        "\n",
        "    X_test_meta = X\n",
        "\n",
        "    for model_name, estimator in self.estimators.items():\n",
        "      pred = estimator.predict(X)\n",
        "      X_test_meta = np.c_[X_test_meta, pred]\n",
        "\n",
        "      self.predictions_by_model[model_name] = pred\n",
        "    \n",
        "    y_pred = self.meta_estimator.predict(X_test_meta)\n",
        "\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "NWPp69ZwTaX3"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimators = {\n",
        "    'dtree': DecisionTreeClassifier(),\n",
        "    'knn' : KNeighborsClassifier(),\n",
        "    'svc' : SVC()\n",
        "}\n",
        "\n",
        "meta_estimator = LogisticRegression(max_iter=500)"
      ],
      "metadata": {
        "id": "iUDvIjS7Z_jo"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blender = Blender(estimators=estimators, meta_estimator=meta_estimator)"
      ],
      "metadata": {
        "id": "lgw9zpm-aOgD"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blender.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "4AfK1eU0aczW"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's compare the models. (For curiosity, for this highly imbalanced dataset we'll use weighted precision, recall and f_beta scores):"
      ],
      "metadata": {
        "id": "hFNOW2CpoC86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support"
      ],
      "metadata": {
        "id": "ryVyUdihfGQy"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score_model(y_true, y_pred):\n",
        "  precision, recall, f_beta, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted', labels=np.unique(y_pred))\n",
        "\n",
        "  scores = {\n",
        "      'precision': precision,\n",
        "      'recall': recall,\n",
        "      'f_beta': f_beta\n",
        "  }\n",
        "  \n",
        "  return scores"
      ],
      "metadata": {
        "id": "dPXpYPlHexqZ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_by_models = {}\n",
        "\n",
        "# XGBClassifier\n",
        "best_xgb = grid_search.best_estimator_\n",
        "y_pred = best_xgb.predict(X_test)\n",
        "\n",
        "scores_by_models['xbg_clf'] = score_model(y_test, y_pred)\n",
        "\n",
        "# Custum Blender\n",
        "y_pred = blender.predict(X_test)\n",
        "scores_by_models['blender'] = score_model(y_test, y_pred)\n",
        "\n",
        "\n",
        "# Base estimators in custom blender\n",
        "for model_name, y_pred in blender.predictions_by_model.items():\n",
        "  scores_by_models[model_name] = score_model(y_test, y_pred)"
      ],
      "metadata": {
        "id": "-XRxLcQ6bQ_4"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame.from_dict(scores_by_models).transpose().sort_values(by=['precision', 'recall', 'f_beta'], ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "05SrY2QHlRvr",
        "outputId": "e5e0edd9-5afe-46d9-8f46-e848eaedf400"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f_beta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>xbg_clf</th>\n",
              "      <td>0.981169</td>\n",
              "      <td>0.980800</td>\n",
              "      <td>0.973039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>svc</th>\n",
              "      <td>0.978667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.989218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dtree</th>\n",
              "      <td>0.973437</td>\n",
              "      <td>0.969600</td>\n",
              "      <td>0.971392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>blender</th>\n",
              "      <td>0.972516</td>\n",
              "      <td>0.978933</td>\n",
              "      <td>0.969271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>0.968955</td>\n",
              "      <td>0.978667</td>\n",
              "      <td>0.969125</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         precision    recall    f_beta\n",
              "xbg_clf   0.981169  0.980800  0.973039\n",
              "svc       0.978667  1.000000  0.989218\n",
              "dtree     0.973437  0.969600  0.971392\n",
              "blender   0.972516  0.978933  0.969271\n",
              "knn       0.968955  0.978667  0.969125"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUEBs-BxqVml",
        "outputId": "80c8b082-d41e-4aca-f419-913d7219c86b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.021333333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conclusions:\n",
        "- These results are obtained, just from one run of the algorithms. A more meaningful results requires averaging over repeated experiments results.\n",
        "\n",
        "- We see that (as expected, I guess) XGBClassifier performs better (with respect to `precision`) that our custom blending ensemble and any other of the blender's base models alone.\n",
        "- Our custom blender performs worse than some its the base estimators. This may be related to the fact that:\n",
        "  - The `knn` base estimator performs comparatively worse than `svc`, and `dtree`, which may lead the blender to find some compromise between the performance of the base models, and choose something _between them_.\n",
        "\n",
        "- **Important:** The results above may be misleading due to the highly imbalance of the dataset labels ($\\approx 2\\%$ of the instances are from the positive class). It may be the case that, even though we split train and test set according to this distribution, the models may have predicted only values from the negative class, for which case the label in `y_test` that are not in `y_pred` (labels $1$) are ignored when computing `precision`, `recall` and `f_beta`."
      ],
      "metadata": {
        "id": "FykjT7J4qjSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8iIsm_8TqXFR"
      },
      "execution_count": 36,
      "outputs": []
    }
  ]
}